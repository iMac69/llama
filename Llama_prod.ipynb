{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVw1mgyxrzt9i/Cq6ujhWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iMac69/llama/blob/main/Llama_prod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Python Environment"
      ],
      "metadata": {
        "id": "LCO73ogWrBMl"
      }
    },
    {
      "source": [
        "import numpy as np"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tjk8dON0sPgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install python3.10-venv\n",
        "On Debian/Ubuntu systems, you need to install the python3-venv package.\n",
        "\n"
      ],
      "metadata": {
        "id": "9Rfe68-attZR"
      }
    },
    {
      "source": [
        "!apt-get update\n",
        "!apt-get -y install python3.10-venv"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PPD-EnaIs6eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Virtual Environment"
      ],
      "metadata": {
        "id": "aqI0TVoFuQOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m venv llama-env\n",
        "!source llama-env/bin/activate"
      ],
      "metadata": {
        "id": "TREGxetWsn3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upgrade pip and install essential Python packages:"
      ],
      "metadata": {
        "id": "mJCTA7fXucZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "u4U-uskDtE-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Llama CLI\n"
      ],
      "metadata": {
        "id": "EMpyVbIhqmM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-toolchain"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Cg2mGWPjqVza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama Model list to determine model ID to download\n"
      ],
      "metadata": {
        "id": "RzaPqBfUqx63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!llama model list"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Ns48rprhq5Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Llama 3.1-8B"
      ],
      "metadata": {
        "id": "scXC7NuE4qgE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!llama download --source meta --model-id Meta-Llama3.1-8B"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7g3aHjO12N7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Prompt-Guard-86M\n",
        "These models are designed for safety and robustness, with modifications to reduce the risk of generating harmful content.\n"
      ],
      "metadata": {
        "id": "U0nnUlLT4vzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./Prompt-Guard-86M"
      ],
      "metadata": {
        "collapsed": true,
        "id": "a2qAp2m54Cxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download 3.1-8B Instruct\n",
        "Improved performance for specicific tasks, like following instructions or creating text."
      ],
      "metadata": {
        "id": "ugugD03BJgOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!llama download --source meta --model-id Meta-Llama3.1-8B-Instruct"
      ],
      "metadata": {
        "id": "HUiyMsquIBwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download 3.1-70B Instruct\n",
        "Improved performance for specicific tasks, like following instructions or creating text.\n",
        "\n"
      ],
      "metadata": {
        "id": "nb7w_PSIK4fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./Llama3.1-70B-Instruct"
      ],
      "metadata": {
        "id": "9WQ5Z0P-YYoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Llama 3.1-70b-Instruct in Google Colab:"
      ],
      "metadata": {
        "id": "N5MmbWeGMm1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"Llama3.1-70B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "VWcyqgx3MxNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Knowledge Base\n",
        "Connecting Llama to vector database using Pinecone"
      ],
      "metadata": {
        "id": "IoMJb1eJNxUl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shsyepQ8VTOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Text from PDFs:"
      ],
      "metadata": {
        "id": "77stLYriVcnH"
      }
    }
  ]
}